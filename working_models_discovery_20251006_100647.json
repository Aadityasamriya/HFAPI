{
  "timestamp": "20251006_100647",
  "discovery_results": {
    "working_models": {
      "text_generation": [
        {
          "model": "Qwen/Qwen2.5-7B-Instruct",
          "response": "Hello! I'm an AI assistant and don't have feelings...",
          "response_time": 0.4999370574951172
        },
        {
          "model": "Qwen/Qwen2.5-72B-Instruct",
          "response": "Hello! I'm doing well, thank you for asking. How c...",
          "response_time": 1.2160005569458008
        },
        {
          "model": "meta-llama/Llama-3.1-8B-Instruct",
          "response": "I'm functioning properly and ready to assist you. ...",
          "response_time": 0.7322311401367188
        },
        {
          "model": "meta-llama/Llama-3.3-70B-Instruct",
          "response": "Hello. I'm doing well, thanks for asking. I'm read...",
          "response_time": 0.7549784183502197
        },
        {
          "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
          "response": "None",
          "response_time": 0.7825908660888672
        },
        {
          "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
          "response": "None",
          "response_time": 0.9278149604797363
        },
        {
          "model": "deepseek-ai/DeepSeek-V3",
          "response": "Hello! I'm just a program, so I don't have feeling...",
          "response_time": 0.8288161754608154
        },
        {
          "model": "google/gemma-2-2b-it",
          "response": "I am an AI assistant, so I do not have feelings. H...",
          "response_time": 0.9112756252288818
        }
      ],
      "code_generation": [
        {
          "model": "Qwen/Qwen2.5-Coder-7B-Instruct",
          "response": "Hello! I'm just a computer program, so I don't hav...",
          "response_time": 1.0043773651123047
        },
        {
          "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
          "response": "Hello! I'm just a computer program, so I don't hav...",
          "response_time": 0.9445481300354004
        },
        {
          "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
          "response": "None",
          "response_time": 0.93324875831604
        },
        {
          "model": "meta-llama/Llama-3.1-8B-Instruct",
          "response": "I'm functioning properly and ready to assist you. ...",
          "response_time": 0.5713293552398682
        }
      ],
      "general_purpose": [
        {
          "model": "Qwen/Qwen2.5-7B-Instruct",
          "response": "Hello! I'm an AI assistant and don't have feelings...",
          "response_time": 0.4540266990661621
        },
        {
          "model": "meta-llama/Llama-3.1-8B-Instruct",
          "response": "I'm functioning properly and ready to assist you. ...",
          "response_time": 0.42569518089294434
        },
        {
          "model": "google/gemma-2-2b-it",
          "response": "I am doing well, thank you. How can I assist you t...",
          "response_time": 0.7235636711120605
        }
      ],
      "reasoning": [
        {
          "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
          "response": "None",
          "response_time": 0.9529528617858887
        },
        {
          "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
          "response": "None",
          "response_time": 0.767535924911499
        }
      ],
      "fallback": [
        {
          "model": "google/gemma-2-2b-it",
          "response": "I am an AI assistant, so I do not have feelings. H...",
          "response_time": 0.7411339282989502
        }
      ]
    },
    "failed_models": {
      "text_generation": [
        {
          "model": "microsoft/Phi-3-mini-4k-instruct",
          "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-3-mini-4k-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
        },
        {
          "model": "microsoft/Phi-3.5-mini-instruct",
          "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-3.5-mini-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
        },
        {
          "model": "microsoft/Phi-4-mini-instruct",
          "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-4-mini-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
        },
        {
          "model": "Qwen/Qwen2.5-1.5B-Instruct",
          "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'Qwen/Qwen2.5-1.5B-Instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
        }
      ],
      "code_generation": [
        {
          "model": "microsoft/Phi-3-mini-4k-instruct",
          "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-3-mini-4k-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
        },
        {
          "model": "microsoft/Phi-4-mini-instruct",
          "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-4-mini-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
        }
      ],
      "general_purpose": [
        {
          "model": "microsoft/Phi-3-mini-4k-instruct",
          "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-3-mini-4k-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
        }
      ],
      "reasoning": [
        {
          "model": "microsoft/Phi-4-mini-instruct",
          "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-4-mini-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
        }
      ],
      "fallback": [
        {
          "model": "microsoft/Phi-3-mini-4k-instruct",
          "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-3-mini-4k-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
        },
        {
          "model": "Qwen/Qwen2.5-1.5B-Instruct",
          "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'Qwen/Qwen2.5-1.5B-Instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
        }
      ]
    },
    "total_working": 18,
    "total_tested": 28,
    "success_rate": 64.28571428571429
  },
  "working_models_by_category": {
    "text_generation": [
      {
        "model": "Qwen/Qwen2.5-7B-Instruct",
        "response": "Hello! I'm an AI assistant and don't have feelings...",
        "response_time": 0.4999370574951172
      },
      {
        "model": "Qwen/Qwen2.5-72B-Instruct",
        "response": "Hello! I'm doing well, thank you for asking. How c...",
        "response_time": 1.2160005569458008
      },
      {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "response": "I'm functioning properly and ready to assist you. ...",
        "response_time": 0.7322311401367188
      },
      {
        "model": "meta-llama/Llama-3.3-70B-Instruct",
        "response": "Hello. I'm doing well, thanks for asking. I'm read...",
        "response_time": 0.7549784183502197
      },
      {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
        "response": "None",
        "response_time": 0.7825908660888672
      },
      {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "response": "None",
        "response_time": 0.9278149604797363
      },
      {
        "model": "deepseek-ai/DeepSeek-V3",
        "response": "Hello! I'm just a program, so I don't have feeling...",
        "response_time": 0.8288161754608154
      },
      {
        "model": "google/gemma-2-2b-it",
        "response": "I am an AI assistant, so I do not have feelings. H...",
        "response_time": 0.9112756252288818
      }
    ],
    "code_generation": [
      {
        "model": "Qwen/Qwen2.5-Coder-7B-Instruct",
        "response": "Hello! I'm just a computer program, so I don't hav...",
        "response_time": 1.0043773651123047
      },
      {
        "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "response": "Hello! I'm just a computer program, so I don't hav...",
        "response_time": 0.9445481300354004
      },
      {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "response": "None",
        "response_time": 0.93324875831604
      },
      {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "response": "I'm functioning properly and ready to assist you. ...",
        "response_time": 0.5713293552398682
      }
    ],
    "general_purpose": [
      {
        "model": "Qwen/Qwen2.5-7B-Instruct",
        "response": "Hello! I'm an AI assistant and don't have feelings...",
        "response_time": 0.4540266990661621
      },
      {
        "model": "meta-llama/Llama-3.1-8B-Instruct",
        "response": "I'm functioning properly and ready to assist you. ...",
        "response_time": 0.42569518089294434
      },
      {
        "model": "google/gemma-2-2b-it",
        "response": "I am doing well, thank you. How can I assist you t...",
        "response_time": 0.7235636711120605
      }
    ],
    "reasoning": [
      {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "response": "None",
        "response_time": 0.9529528617858887
      },
      {
        "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
        "response": "None",
        "response_time": 0.767535924911499
      }
    ],
    "fallback": [
      {
        "model": "google/gemma-2-2b-it",
        "response": "I am an AI assistant, so I do not have feelings. H...",
        "response_time": 0.7411339282989502
      }
    ]
  },
  "failed_models_by_category": {
    "text_generation": [
      {
        "model": "microsoft/Phi-3-mini-4k-instruct",
        "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-3-mini-4k-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
      },
      {
        "model": "microsoft/Phi-3.5-mini-instruct",
        "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-3.5-mini-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
      },
      {
        "model": "microsoft/Phi-4-mini-instruct",
        "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-4-mini-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
      },
      {
        "model": "Qwen/Qwen2.5-1.5B-Instruct",
        "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'Qwen/Qwen2.5-1.5B-Instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
      }
    ],
    "code_generation": [
      {
        "model": "microsoft/Phi-3-mini-4k-instruct",
        "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-3-mini-4k-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
      },
      {
        "model": "microsoft/Phi-4-mini-instruct",
        "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-4-mini-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
      }
    ],
    "general_purpose": [
      {
        "model": "microsoft/Phi-3-mini-4k-instruct",
        "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-3-mini-4k-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
      }
    ],
    "reasoning": [
      {
        "model": "microsoft/Phi-4-mini-instruct",
        "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-4-mini-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
      }
    ],
    "fallback": [
      {
        "model": "microsoft/Phi-3-mini-4k-instruct",
        "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'microsoft/Phi-3-mini-4k-instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
      },
      {
        "model": "Qwen/Qwen2.5-1.5B-Instruct",
        "error": "Inference error: HTTP 400: {\"error\":{\"message\":\"The requested model 'Qwen/Qwen2.5-1.5B-Instruct' is not supported by any provider you have enabled.\",\"type\":\"invalid_request_error\",\"param\":\"model\",\"code\":\"model_not_supported\"}}"
      }
    ]
  }
}